{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### TUGAS 1"
      ],
      "metadata": {
        "id": "3HBeyNGAue01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "\n",
        "# Contoh dataset (buat dummy data)\n",
        "data = pd.DataFrame({\n",
        "    'luas': [50, 60, 70, 80, 90],\n",
        "    'harga': [500, 600, 700, 800, 900]\n",
        "})\n",
        "\n",
        "X = data[['luas']]\n",
        "y = data[['harga']]\n",
        "\n",
        "# Normalisasi\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(y)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "def train_and_evaluate_regression_model(learning_rate, X_train, y_train, X_test, y_test):\n",
        "    print(f\"\\n--- Training with Learning Rate: {learning_rate} ---\")\n",
        "\n",
        "    # Model\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(10, activation='relu', input_shape=(1,)),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "    # Kompilasi dengan optimizer Adam dan learning_rate yang ditentukan\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='mse')\n",
        "\n",
        "    # Latih model\n",
        "    history = model.fit(X_train, y_train, epochs=100, verbose=0) # verbose=0 untuk mengurangi output\n",
        "\n",
        "    # Evaluasi\n",
        "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f\"Final Loss (MSE) with LR {learning_rate}: {loss:.4f}\")\n",
        "    return loss\n",
        "\n",
        "# --- Bandingkan hasil dengan learning rate yang berbeda ---\n",
        "\n",
        "# Learning rate asli (default Adam = 0.001)\n",
        "original_lr = 0.001\n",
        "original_loss = train_and_evaluate_regression_model(original_lr, X_train, y_train, X_test, y_test)\n",
        "\n",
        "# Learning rate yang diubah (misalnya lebih besar)\n",
        "modified_lr_higher = 0.01\n",
        "modified_loss_higher = train_and_evaluate_regression_model(modified_lr_higher, X_train, y_train, X_test, y_test)\n",
        "\n",
        "# Learning rate yang diubah (misalnya lebih kecil)\n",
        "modified_lr_lower = 0.0001\n",
        "modified_loss_lower = train_and_evaluate_regression_model(modified_lr_lower, X_train, y_train, X_test, y_test)\n",
        "\n",
        "print(\"\\n--- Perbandingan Final Losses (MSE) ---\")\n",
        "print(f\"LR {original_lr}:      {original_loss:.4f}\")\n",
        "print(f\"LR {modified_lr_higher}: {modified_loss_higher:.4f}\")\n",
        "print(f\"LR {modified_lr_lower}:  {modified_loss_lower:.4f}\")\n",
        "\n",
        "# Mencari learning rate terbaik\n",
        "best_loss = min(original_loss, modified_loss_higher, modified_loss_lower)\n",
        "if best_loss == original_loss:\n",
        "    print(f\"Learning rate {original_lr} memberikan loss terendah.\")\n",
        "elif best_loss == modified_loss_higher:\n",
        "    print(f\"Learning rate {modified_lr_higher} memberikan loss terendah.\")\n",
        "else:\n",
        "    print(f\"Learning rate {modified_lr_lower} memberikan loss terendah.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if5gPhNwueTX",
        "outputId": "a4b7f8d8-6c98-49c2-d74c-5b2cb2901bba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training with Learning Rate: 0.001 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Loss (MSE) with LR 0.001: 0.8964\n",
            "\n",
            "--- Training with Learning Rate: 0.01 ---\n",
            "Final Loss (MSE) with LR 0.01: 0.0089\n",
            "\n",
            "--- Training with Learning Rate: 0.0001 ---\n",
            "Final Loss (MSE) with LR 0.0001: 0.6612\n",
            "\n",
            "--- Perbandingan Final Losses (MSE) ---\n",
            "LR 0.001:      0.8964\n",
            "LR 0.01: 0.0089\n",
            "LR 0.0001:  0.6612\n",
            "Learning rate 0.01 memberikan loss terendah.\n"
          ]
        }
      ]
    }
  ]
}